{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_descriptions(tokens):\n",
    "    '''\n",
    "    Remove stopwords;\n",
    "\n",
    "    \n",
    "    Remove punctuation\n",
    "    '''\n",
    "    stop_words = stopwords.words('english')\n",
    "    res = [w.lower() for w in tokens if not w in stop_words] ## Remove stopwords\n",
    "    res_punc = [w for w in res if w.isalpha()] ## Remove punctuation\n",
    "    return res_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [word_tokenize(x) for x in train]\n",
    "clean_tokens = [clean_descriptions(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() ## numbers of cores in the computer\n",
    "model = Word2Vec(min_count=1,\n",
    "                window=5,\n",
    "                size=50,\n",
    "                sample=6e-5,\n",
    "                alpha=0.03,\n",
    "                min_alpha=0.0007,\n",
    "                negative=20,\n",
    "                workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time to train the model: 0.5962 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "model.train(clean_tokens, total_examples=model.corpus_count, epochs=100)\n",
    "print(f\"Time to train the model: {round((time() - t) / 60, 4)} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('gun', 0.620539128780365),\n",
       " ('shui', 0.6091277003288269),\n",
       " ('owners', 0.6024693250656128),\n",
       " ('mass', 0.5929380655288696),\n",
       " ('feng', 0.5868189334869385),\n",
       " ('carry', 0.5839115381240845),\n",
       " ('shootings', 0.5771595239639282),\n",
       " ('educate', 0.5662846565246582),\n",
       " ('nightclubs', 0.5634212493896484),\n",
       " ('educators', 0.5628822445869446)]"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "''' Checking for similar words '''\n",
    "model.wv.most_similar(['guns'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/word2vec_model.model')"
   ]
  },
  {
   "source": [
    "### Load test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test.pkl', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = random.sample(test, 100)"
   ]
  },
  {
   "source": [
    "### Prepare test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [word_tokenize(x) for x in test]\n",
    "clean_test_data = [clean_descriptions(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word logline not found in vocab\nWord cho not found in vocab\nWord disbanded not found in vocab\nWord garagiste not found in vocab\nWord fried not found in vocab\nWord reposted not found in vocab\nWord steenburgen not found in vocab\nWord chastising not found in vocab\nWord maye not found in vocab\nWord alunageorge not found in vocab\nWord cosima not found in vocab\nWord deke not found in vocab\nWord dickerson not found in vocab\nWord attic not found in vocab\nWord romancing not found in vocab\n"
     ]
    }
   ],
   "source": [
    "words, vectors = [], []\n",
    "for desc in clean_test_data: ## Iterate over descriptions in test data\n",
    "    for word in desc: ## Iterate over words in descriptions\n",
    "        try:\n",
    "            vectors.append(model.wv.get_vector(word))\n",
    "            words.append(word)\n",
    "        except KeyError:\n",
    "            print(f'Word {word} not found in vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "911"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data/words.txt', words, fmt='%s')\n",
    "np.save('data/vectors.npy', vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}